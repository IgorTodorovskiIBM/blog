---
layout:         post
title:          "Optimizing Git Performance on z/OS"
author:         "Igor Todorovski"
header-img:     "img/in-post/tracing_bg.jpg"
catalog:         true
hidden: true
tags:
    - git
    - performance
    - z/OS
---

## Optimizing Git Performance

As developers, we rely heavily on Git for version control.  However, as repositories grow in size and history, Git operations can become noticeably slower.  This can impact our daily workflow, slow down CI/CD pipelines, and negatively affect the entire development process.

Recently, I investigated various Git performance optimization techniques, and I decided to put them to the test.

My goal was to understand the practical impact of these strategies. Here's a breakdown of my research and findings.

We'll explore the strategies that provided the most significant performance improvements first.

### 1. Data Reduction Strategies

The idea behind many this is simple: reduce the amount of data Git has to handle.

Let's examine how this works in practice.

#### Shallow Clones: Reducing the History

**Purpose:** Shallow clones are ideal when you don't need the full commit history. By cloning with a limited depth, you significantly reduce the amount of data transferred, making cloning much faster. This is incredibly useful in CI/CD or for quickly getting the latest codebase.

**Benefits:**

* **Reduced Cloning Time:**  Save time, especially for repositories with a long history.
* **Lower Bandwidth Usage:**  Less data transfer, important for large teams.
* **Reduced Disk Footprint:**  Shallow clones take up significantly less disk space.

**Experiment on Perl 5:**  As an experiment, I cloned the Perl 5 repository ([https://github.com/Perl/perl5](https://github.com/Perl/perl5)), first with a full clone and then with a shallow clone (depth 1).  I ran these tests on a z/OS 3.1 z15 machine.

```
    # Baseline: Full Clone
    time git clone [https://github.com/Perl/perl5](https://github.com/Perl/perl5) perl5-full-clone

    # Shallow Clone with depth 1
    time git clone --depth=1 [https://github.com/Perl/perl5](https://github.com/Perl/perl5) perl5-shallow-clone
```


The results were as follows:

```
    # Baseline: Full Clone
    real     0m46.611s
    user     1m16.479s
    sys      0m25.493s

    # Shallow Clone with depth 1
    real     0m4.447s
    user     0m2.328s
    sys      0m0.776s
```


As you can see, shallow cloning on the Perl 5 repository showed a dramatic improvement! The clone time was reduced from over 46 seconds to just over 4 seconds, a reduction of over 90%! The repository size was also significantly reduced as only the latest commit was downloaded, instead of the entire history. For scenarios where commit history isn't immediately needed, shallow clones make a clear difference, especially in CI/CD pipelines.

### Avoiding Downloading Large Binaries (Blob Filtering)

**Purpose**: Repositories can accumulate large binary files over time. If these binaries are not needed for every operation, you can instruct Git to filter these out during the cloning process. This helps in managing bandwidth and disk space effectively, and reduces clone time. The `--filter=blob:none` option prevents Git from downloading any large file blobs.

I cloned the Perl 5 repository again, this time using the `--filter=blob:none` option to exclude binary blobs.

```
    rm -rf perl5; time git clone --filter=blob:none  git@github.com:Perl/perl5.git
```


The results were:

```
    real     0m15.333s
    user     0m9.057s
    sys      0m3.019s
```


Using `--filter=blob:none` reduced the clone time to approximately 15 seconds, significantly faster than the baseline full clone of 46 seconds. This technique is a great way to reduce clone time, while maintaining history for repositories where binaries are not essential for maintenance.

### Cloning Only a Single Branch and Avoiding Tags

**Purpose:** By default, `git clone` clones all branches and tags.  If you are only interested in a single branch, and tags are not immediately necessary, cloning only a single branch and excluding tags can reduce the amount of data transferred and speed up the clone operation. The `--no-tags` option skips downloading tags, and `--single-branch` clones only the specified branch.

I cloned the Perl 5 repository again, this time using the `--no-tags` and `--single-branch` options.

```
    rm -rf perl5; time git clone  --no-tags --single-branch git@github.com:Perl/perl5.git
```


The results were:

```
    real     0m34.867s
    user     1m2.789s
    sys      0m20.930s
```


Cloning a single branch without tags took approximately 35 seconds, which is faster than the full clone baseline, but not as fast as `--filter=blob:none`.  However, it still offers a noticeable improvement by reducing the data transferred, especially in repositories with a large number of branches and tags.

#### Sparse Checkouts: Focus on What You Need

**Purpose:** Sparse checkouts allow you to download only a specific subset of directories from a repository into your working directory.  This is perfect for monorepos or large projects where you only work within certain modules or components.

**Benefits:**

* **Reduced Working Directory Size:**  Save disk space by only checking out necessary files.
* **Faster `git status` and Checkout Operations:**  Git has less data to track and manage in your working directory, improving command speed.

Using a sparse checkout on the Perl 5 repository, I aimed to exclude the `cpan/` directory, which contains CPAN module-related code and is approximately 26mb in size. I used the following script:

```
    # spare-checkout.sh

    # Initialize an empty repository
    rm -rf perl5-sparse-empty-test
    mkdir perl5-sparse-empty-test
    cd perl5-sparse-empty-test
    git init

    # Add the Perl 5 repository as a remote
    git remote add origin [https://github.com/Perl/perl5](https://github.com/Perl/perl5)

    # Ignore the cpan directory
    git config core.sparseCheckoutCone false
    git sparse-checkout init --no-cone
    git sparse-checkout set "/*"
    git sparse-checkout add '!cpan' # ignore listing dir

    git fetch origin blead

    git checkout blead
```


Running this script with sparse checkout commands yielded a total time of:

```
    real     0m42.361s
    user     1m7.524s
    sys      0m22.508s
```

When the sparse-checkout commands are commented out, essentially performing a full clone, the time taken was:

```
    real     0m43.325s
    user     1m8.081s
    sys      0m22.694s
```


While the time difference isn't dramatically significant in this specific test, sparse checkout successfully saved approximately 26mb of data by excluding the `cpan` directory.  The real benefit of sparse checkout shines when dealing with much larger repositories and when you need to work with only specific parts of the codebase, significantly reducing disk usage and potentially improving the speed of various Git commands within the working directory.

### Working-Tree-Encoding: Mind the Conversion Costs

If your project uses working-tree-encoding or zos-working-tree-encoding, be aware of the potential performance overhead. Encoding conversions handled by iconv can add CPU load, especially with global wildcard configurations. Targeted encoding rules are recommended to minimize this impact.

To illustrate this, I created a fork of the Perl 5 repository with a `.gitattributes` file that would apply `zos-working-tree-encoding=ibm-1047` to all text files:

[https://github.com/IgorTodorovskiIBM/perl5](https://github.com/IgorTodorovskiIBM/perl5)

```
    # .gitattributes
    * text zos-working-tree-encoding=ibm-1047
```


Cloning this repository:

```
    time git clone git@github.com:IgorTodorovskiIBM/perl5.git
```


The encoding conversion, applied globally, added approximately 3 seconds to the total clone time compared to cloning the original repository without the encoding attribute. While 3 seconds might seem small, it's a factor to consider, especially in scenarios involving large repositories or frequent Git operations. For projects using working-tree-encoding, carefully consider the scope of encoding conversions to mitigate potential performance impacts.

### Conclusion

For a list of additional performance considerations, visit the Git on z/OS guide here: https://github.com/zopencommunity/gitport?tab=readme-ov-file#git-performance-considerations.


